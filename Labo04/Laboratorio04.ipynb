{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio de programación Regresión Lineal Multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilizado para manejos de directorios y rutas\n",
    "import os\n",
    "\n",
    "# Computacion vectorial y cientifica para python\n",
    "import numpy as np\n",
    "\n",
    "# Librerias para graficación (trazado de gráficos)\n",
    "from matplotlib import pyplot\n",
    "from mpl_toolkits.mplot3d import Axes3D  # Necesario para graficar superficies 3D\n",
    "\n",
    "# llama a matplotlib a embeber graficas dentro de los cuadernillos\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Regresión lineal con multiples variables\n",
    "\n",
    "Se implementa la regresion lineal multivariable para predecir el precio de las casas. El archivo `Datasets/ex1data2.txt` contiene un conjunto de entrenamiento de precios de casas en Portland, Oregon. La primera columna es el tamaño de la casa en metros cuadrados, la segunda columna es el numero de cuartos, y la tercera columna es el precio de la casa. \n",
    "\n",
    "<a id=\"section4\"></a>\n",
    "### 2.1 Normalización de caracteristicas\n",
    "\n",
    "Al visualizar los datos se puede observar que las caracteristicas tienen diferentes magnitudes, por lo cual se debe transformar cada valor en una escala de valores similares, esto con el fin de que el descenso por el gradiente pueda converger mas rapidamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  X[:,0]  X[:, 1]  X[:, 2]  X[:, 3]  X[:, 4]     y\n",
      "--------------------------------------------------\n",
      "       3       2      40       1       9       357\n",
      "       2       1      20       1       9       153\n",
      "       1       3      20       2       1        71\n",
      "       2       1      40       0       2       163\n",
      "       1       3      20       1       9       108\n",
      "       3       1      20       2       9       324\n",
      "       3       1      20       0       6       250\n",
      "       2       2      40       0       9       176\n",
      "       2       1      20       1       5       150\n",
      "       3       2      20       1       5       288\n"
     ]
    }
   ],
   "source": [
    "# Cargar datos\n",
    "#data = np.loadtxt(os.path.join('Datasets', 'ex1data2.txt'), delimiter=',')\n",
    "data = np.loadtxt(os.path.join('data_cobro.txt'), delimiter=',')\n",
    "X = data[:, :5]\n",
    "y = data[:, 5]\n",
    "m = y.size\n",
    "\n",
    "# imprimir algunos puntos de datos\n",
    "print('{:>8s} {:>8s} {:>8s} {:>8s} {:>8s} {:>5s}'.format('X[:,0]', 'X[:, 1]', 'X[:, 2]', 'X[:, 3]', 'X[:, 4]', 'y'))\n",
    "print('-'*50)\n",
    "for i in range(10):\n",
    "    print('{:8.0f}{:8.0f}{:8.0f}{:8.0f}{:8.0f}{:10.0f}'.format(X[i, 0], X[i, 1], X[i,2], X[i,3], X[i,4], y[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La desviación estándar es una forma de medir cuánta variación hay en el rango de valores de una característica en particular (la mayoría de los puntos caeran en un rango de ± 2 en relación a la desviaciones estándar de la media); esta es una alternativa a tomar el rango de valores (max-min). En `numpy`, se puede usar la función `std` para calcular la desviacion estandar. \n",
    "\n",
    "Por ejemplo, la caracteristica`X[:, 0]` contiene todos los valores de $x_1$ (tamaño de las casas) en el conjunto de entrenamiento, entonces `np.std(X[:, 0])` calcula la desviacion estandar de los tamaños de las casas.\n",
    "En el momento en que se llama a la función `featureNormalize`, la columna adicional de unos correspondiente a $ x_0 = 1 $ aún no se ha agregado a $ X $. \n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "**Notas para la implementación:** Cuando se normalize una caracteristica, es importante almacenar los valores usados para la normalización - el valor de la media y el valor de la desviación estandar usado para los calculos. Despues de aprender los parametros del modelo, se deseara predecir los precios de casas que no se han visto antes. Dado un nuevo valor de x (area del living room y el numero de dormitorios), primero se debe normalizar x usando la media y la desviacion estandar que se empleo anteriormente en el conjunto de entrenamiento para entrenar el modelo.\n",
    "</div>\n",
    "<a id=\"featureNormalize\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  featureNormalize(X):\n",
    "    X_norm = X.copy()\n",
    "    mu = np.zeros(X.shape[1])\n",
    "    sigma = np.zeros(X.shape[1])\n",
    "\n",
    "    mu = np.mean(X, axis = 0)\n",
    "    sigma = np.std(X, axis = 0)\n",
    "    X_norm = (X - mu) / sigma\n",
    "    \n",
    "    return X_norm, mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.  2. 40.  1.  9.]\n",
      " [ 2.  1. 20.  1.  9.]\n",
      " [ 1.  3. 20.  2.  1.]\n",
      " [ 2.  1. 40.  0.  2.]\n",
      " [ 1.  3. 20.  1.  9.]\n",
      " [ 3.  1. 20.  2.  9.]\n",
      " [ 3.  1. 20.  0.  6.]\n",
      " [ 2.  2. 40.  0.  9.]\n",
      " [ 2.  1. 20.  1.  5.]\n",
      " [ 3.  2. 20.  1.  5.]\n",
      " [ 1.  2. 60.  1.  6.]\n",
      " [ 1.  1. 40.  0.  5.]\n",
      " [ 3.  3. 60.  1.  8.]\n",
      " [ 2.  1. 60.  1.  1.]\n",
      " [ 3.  3. 60.  1.  4.]\n",
      " [ 1.  1. 20.  1.  1.]\n",
      " [ 3.  1. 40.  2.  8.]\n",
      " [ 3.  3. 20.  0.  4.]\n",
      " [ 3.  1. 20.  1.  5.]\n",
      " [ 3.  3. 60.  2.  8.]\n",
      " [ 3.  3. 40.  2.  6.]\n",
      " [ 2.  2. 40.  1.  7.]\n",
      " [ 1.  1. 40.  1.  5.]\n",
      " [ 3.  3. 40.  0.  6.]\n",
      " [ 2.  3. 60.  1.  9.]\n",
      " [ 1.  1. 60.  0.  1.]\n",
      " [ 2.  2. 40.  1.  4.]\n",
      " [ 2.  3. 20.  2.  3.]\n",
      " [ 1.  1. 20.  0.  1.]\n",
      " [ 2.  3. 60.  2.  3.]\n",
      " [ 2.  2. 40.  0.  5.]\n",
      " [ 1.  2. 60.  0.  3.]\n",
      " [ 2.  1. 20.  0.  8.]\n",
      " [ 1.  1. 40.  0.  6.]\n",
      " [ 2.  3. 40.  0.  1.]\n",
      " [ 3.  3. 60.  0.  9.]\n",
      " [ 2.  3. 20.  2.  3.]\n",
      " [ 2.  2. 40.  1.  5.]\n",
      " [ 1.  3. 40.  0.  7.]\n",
      " [ 2.  3. 20.  1.  9.]\n",
      " [ 3.  3. 20.  2.  2.]\n",
      " [ 2.  2. 60.  0.  1.]\n",
      " [ 2.  1. 40.  1.  9.]\n",
      " [ 3.  2. 60.  0.  1.]\n",
      " [ 2.  3. 20.  2.  1.]\n",
      " [ 1.  1. 40.  1.  9.]\n",
      " [ 3.  1. 20.  0.  5.]\n",
      " [ 1.  1. 40.  1.  2.]\n",
      " [ 2.  2. 60.  0.  9.]\n",
      " [ 1.  3. 60.  2.  9.]\n",
      " [ 1.  1. 40.  0.  8.]\n",
      " [ 1.  1. 40.  2.  3.]\n",
      " [ 2.  1. 40.  1.  4.]\n",
      " [ 2.  2. 60.  2.  3.]\n",
      " [ 2.  3. 60.  0.  1.]\n",
      " [ 1.  1. 60.  0.  1.]\n",
      " [ 2.  3. 60.  0.  3.]\n",
      " [ 3.  3. 20.  0.  6.]\n",
      " [ 1.  3. 40.  2.  5.]\n",
      " [ 2.  2. 20.  2.  1.]\n",
      " [ 1.  2. 40.  2.  6.]\n",
      " [ 2.  3. 40.  2.  2.]\n",
      " [ 2.  1. 20.  1.  5.]\n",
      " [ 2.  2. 40.  2.  8.]\n",
      " [ 1.  1. 20.  1.  8.]\n",
      " [ 2.  3. 20.  2.  9.]\n",
      " [ 1.  2. 60.  1.  8.]\n",
      " [ 2.  3. 20.  2.  5.]\n",
      " [ 3.  2. 40.  1.  9.]\n",
      " [ 1.  2. 40.  0.  6.]\n",
      " [ 2.  3. 40.  1.  7.]\n",
      " [ 3.  3. 40.  2.  4.]\n",
      " [ 1.  3. 40.  0.  7.]\n",
      " [ 2.  2. 20.  1.  3.]\n",
      " [ 1.  1. 60.  0.  7.]\n",
      " [ 3.  3. 60.  0.  3.]\n",
      " [ 2.  1. 20.  2.  8.]\n",
      " [ 2.  1. 60.  2.  5.]\n",
      " [ 2.  1. 40.  2.  1.]\n",
      " [ 2.  1. 20.  1.  5.]\n",
      " [ 3.  2. 20.  0.  5.]\n",
      " [ 2.  1. 20.  1.  9.]\n",
      " [ 2.  2. 60.  0.  4.]\n",
      " [ 3.  2. 60.  0.  8.]\n",
      " [ 1.  1. 20.  0.  4.]\n",
      " [ 2.  3. 40.  2.  8.]\n",
      " [ 2.  1. 40.  1.  4.]\n",
      " [ 2.  1. 20.  0.  2.]\n",
      " [ 2.  2. 40.  2.  6.]\n",
      " [ 3.  2. 20.  2.  2.]\n",
      " [ 2.  3. 60.  2.  8.]\n",
      " [ 3.  3. 40.  1.  3.]\n",
      " [ 1.  1. 20.  2.  9.]\n",
      " [ 1.  2. 60.  1.  1.]\n",
      " [ 3.  1. 20.  2.  4.]\n",
      " [ 3.  2. 20.  2.  9.]\n",
      " [ 3.  1. 60.  1.  4.]\n",
      " [ 2.  3. 60.  1.  6.]\n",
      " [ 2.  1. 60.  1.  4.]\n",
      " [ 2.  3. 20.  2.  8.]\n",
      " [ 2.  1. 60.  0.  1.]\n",
      " [ 3.  2. 40.  2.  6.]\n",
      " [ 1.  3. 20.  0.  7.]\n",
      " [ 2.  2. 60.  0.  9.]\n",
      " [ 3.  3. 40.  1.  1.]\n",
      " [ 1.  2. 60.  1.  2.]\n",
      " [ 1.  2. 40.  2.  7.]\n",
      " [ 3.  3. 60.  1.  5.]\n",
      " [ 3.  1. 60.  2.  3.]\n",
      " [ 3.  1. 60.  2.  1.]\n",
      " [ 3.  1. 40.  0.  1.]\n",
      " [ 2.  3. 40.  0.  7.]\n",
      " [ 1.  1. 40.  2.  5.]\n",
      " [ 1.  1. 60.  2.  7.]\n",
      " [ 2.  1. 60.  2.  5.]\n",
      " [ 3.  1. 60.  1.  8.]\n",
      " [ 1.  3. 20.  1.  2.]\n",
      " [ 1.  1. 40.  0.  7.]\n",
      " [ 1.  1. 60.  2.  2.]\n",
      " [ 2.  3. 40.  1.  5.]\n",
      " [ 2.  1. 60.  1.  3.]\n",
      " [ 2.  1. 60.  0.  6.]\n",
      " [ 2.  2. 40.  1.  6.]\n",
      " [ 2.  1. 20.  1.  9.]\n",
      " [ 1.  1. 60.  2.  1.]\n",
      " [ 3.  2. 20.  2.  7.]\n",
      " [ 1.  2. 40.  2.  6.]\n",
      " [ 3.  1. 40.  0.  2.]\n",
      " [ 2.  1. 60.  0.  2.]\n",
      " [ 2.  1. 40.  0.  3.]\n",
      " [ 3.  2. 40.  0.  6.]\n",
      " [ 1.  1. 40.  1.  8.]\n",
      " [ 2.  3. 40.  2.  1.]\n",
      " [ 1.  1. 20.  1.  4.]\n",
      " [ 3.  3. 40.  1.  7.]\n",
      " [ 3.  1. 40.  0.  6.]\n",
      " [ 2.  2. 40.  2.  1.]\n",
      " [ 3.  2. 40.  0.  4.]\n",
      " [ 1.  1. 40.  1.  7.]\n",
      " [ 1.  3. 60.  0.  3.]\n",
      " [ 1.  1. 40.  0.  8.]\n",
      " [ 1.  2. 60.  1.  3.]\n",
      " [ 3.  1. 40.  1.  4.]\n",
      " [ 2.  2. 40.  2.  4.]\n",
      " [ 2.  1. 60.  0.  7.]\n",
      " [ 3.  2. 60.  1.  5.]\n",
      " [ 3.  3. 20.  1.  6.]\n",
      " [ 3.  2. 60.  1.  7.]\n",
      " [ 2.  1. 60.  2.  8.]\n",
      " [ 3.  2. 60.  2.  4.]]\n",
      "Media calculada: [ 2.01333333  1.88       41.06666667  0.99333333  5.07333333]\n",
      "Desviación estandar calculada: [ 0.76582563  0.84       15.62675768  0.80412824  2.63842546]\n",
      "[[ 1.28836988  0.14285714 -0.06825899  0.00829055  1.48826136]\n",
      " [-0.0174104  -1.04761905 -1.34811502  0.00829055  1.48826136]\n",
      " [-1.32319068  1.33333333 -1.34811502  1.2518733  -1.54385007]\n",
      " [-0.0174104  -1.04761905 -0.06825899 -1.23529219 -1.16483614]\n",
      " [-1.32319068  1.33333333 -1.34811502  0.00829055  1.48826136]\n",
      " [ 1.28836988 -1.04761905 -1.34811502  1.2518733   1.48826136]\n",
      " [ 1.28836988 -1.04761905 -1.34811502 -1.23529219  0.35121957]\n",
      " [-0.0174104   0.14285714 -0.06825899 -1.23529219  1.48826136]\n",
      " [-0.0174104  -1.04761905 -1.34811502  0.00829055 -0.02779435]\n",
      " [ 1.28836988  0.14285714 -1.34811502  0.00829055 -0.02779435]\n",
      " [-1.32319068  0.14285714  1.21159704  0.00829055  0.35121957]\n",
      " [-1.32319068 -1.04761905 -0.06825899 -1.23529219 -0.02779435]\n",
      " [ 1.28836988  1.33333333  1.21159704  0.00829055  1.10924743]\n",
      " [-0.0174104  -1.04761905  1.21159704  0.00829055 -1.54385007]\n",
      " [ 1.28836988  1.33333333  1.21159704  0.00829055 -0.40680828]\n",
      " [-1.32319068 -1.04761905 -1.34811502  0.00829055 -1.54385007]\n",
      " [ 1.28836988 -1.04761905 -0.06825899  1.2518733   1.10924743]\n",
      " [ 1.28836988  1.33333333 -1.34811502 -1.23529219 -0.40680828]\n",
      " [ 1.28836988 -1.04761905 -1.34811502  0.00829055 -0.02779435]\n",
      " [ 1.28836988  1.33333333  1.21159704  1.2518733   1.10924743]\n",
      " [ 1.28836988  1.33333333 -0.06825899  1.2518733   0.35121957]\n",
      " [-0.0174104   0.14285714 -0.06825899  0.00829055  0.7302335 ]\n",
      " [-1.32319068 -1.04761905 -0.06825899  0.00829055 -0.02779435]\n",
      " [ 1.28836988  1.33333333 -0.06825899 -1.23529219  0.35121957]\n",
      " [-0.0174104   1.33333333  1.21159704  0.00829055  1.48826136]\n",
      " [-1.32319068 -1.04761905  1.21159704 -1.23529219 -1.54385007]\n",
      " [-0.0174104   0.14285714 -0.06825899  0.00829055 -0.40680828]\n",
      " [-0.0174104   1.33333333 -1.34811502  1.2518733  -0.78582221]\n",
      " [-1.32319068 -1.04761905 -1.34811502 -1.23529219 -1.54385007]\n",
      " [-0.0174104   1.33333333  1.21159704  1.2518733  -0.78582221]\n",
      " [-0.0174104   0.14285714 -0.06825899 -1.23529219 -0.02779435]\n",
      " [-1.32319068  0.14285714  1.21159704 -1.23529219 -0.78582221]\n",
      " [-0.0174104  -1.04761905 -1.34811502 -1.23529219  1.10924743]\n",
      " [-1.32319068 -1.04761905 -0.06825899 -1.23529219  0.35121957]\n",
      " [-0.0174104   1.33333333 -0.06825899 -1.23529219 -1.54385007]\n",
      " [ 1.28836988  1.33333333  1.21159704 -1.23529219  1.48826136]\n",
      " [-0.0174104   1.33333333 -1.34811502  1.2518733  -0.78582221]\n",
      " [-0.0174104   0.14285714 -0.06825899  0.00829055 -0.02779435]\n",
      " [-1.32319068  1.33333333 -0.06825899 -1.23529219  0.7302335 ]\n",
      " [-0.0174104   1.33333333 -1.34811502  0.00829055  1.48826136]\n",
      " [ 1.28836988  1.33333333 -1.34811502  1.2518733  -1.16483614]\n",
      " [-0.0174104   0.14285714  1.21159704 -1.23529219 -1.54385007]\n",
      " [-0.0174104  -1.04761905 -0.06825899  0.00829055  1.48826136]\n",
      " [ 1.28836988  0.14285714  1.21159704 -1.23529219 -1.54385007]\n",
      " [-0.0174104   1.33333333 -1.34811502  1.2518733  -1.54385007]\n",
      " [-1.32319068 -1.04761905 -0.06825899  0.00829055  1.48826136]\n",
      " [ 1.28836988 -1.04761905 -1.34811502 -1.23529219 -0.02779435]\n",
      " [-1.32319068 -1.04761905 -0.06825899  0.00829055 -1.16483614]\n",
      " [-0.0174104   0.14285714  1.21159704 -1.23529219  1.48826136]\n",
      " [-1.32319068  1.33333333  1.21159704  1.2518733   1.48826136]\n",
      " [-1.32319068 -1.04761905 -0.06825899 -1.23529219  1.10924743]\n",
      " [-1.32319068 -1.04761905 -0.06825899  1.2518733  -0.78582221]\n",
      " [-0.0174104  -1.04761905 -0.06825899  0.00829055 -0.40680828]\n",
      " [-0.0174104   0.14285714  1.21159704  1.2518733  -0.78582221]\n",
      " [-0.0174104   1.33333333  1.21159704 -1.23529219 -1.54385007]\n",
      " [-1.32319068 -1.04761905  1.21159704 -1.23529219 -1.54385007]\n",
      " [-0.0174104   1.33333333  1.21159704 -1.23529219 -0.78582221]\n",
      " [ 1.28836988  1.33333333 -1.34811502 -1.23529219  0.35121957]\n",
      " [-1.32319068  1.33333333 -0.06825899  1.2518733  -0.02779435]\n",
      " [-0.0174104   0.14285714 -1.34811502  1.2518733  -1.54385007]\n",
      " [-1.32319068  0.14285714 -0.06825899  1.2518733   0.35121957]\n",
      " [-0.0174104   1.33333333 -0.06825899  1.2518733  -1.16483614]\n",
      " [-0.0174104  -1.04761905 -1.34811502  0.00829055 -0.02779435]\n",
      " [-0.0174104   0.14285714 -0.06825899  1.2518733   1.10924743]\n",
      " [-1.32319068 -1.04761905 -1.34811502  0.00829055  1.10924743]\n",
      " [-0.0174104   1.33333333 -1.34811502  1.2518733   1.48826136]\n",
      " [-1.32319068  0.14285714  1.21159704  0.00829055  1.10924743]\n",
      " [-0.0174104   1.33333333 -1.34811502  1.2518733  -0.02779435]\n",
      " [ 1.28836988  0.14285714 -0.06825899  0.00829055  1.48826136]\n",
      " [-1.32319068  0.14285714 -0.06825899 -1.23529219  0.35121957]\n",
      " [-0.0174104   1.33333333 -0.06825899  0.00829055  0.7302335 ]\n",
      " [ 1.28836988  1.33333333 -0.06825899  1.2518733  -0.40680828]\n",
      " [-1.32319068  1.33333333 -0.06825899 -1.23529219  0.7302335 ]\n",
      " [-0.0174104   0.14285714 -1.34811502  0.00829055 -0.78582221]\n",
      " [-1.32319068 -1.04761905  1.21159704 -1.23529219  0.7302335 ]\n",
      " [ 1.28836988  1.33333333  1.21159704 -1.23529219 -0.78582221]\n",
      " [-0.0174104  -1.04761905 -1.34811502  1.2518733   1.10924743]\n",
      " [-0.0174104  -1.04761905  1.21159704  1.2518733  -0.02779435]\n",
      " [-0.0174104  -1.04761905 -0.06825899  1.2518733  -1.54385007]\n",
      " [-0.0174104  -1.04761905 -1.34811502  0.00829055 -0.02779435]\n",
      " [ 1.28836988  0.14285714 -1.34811502 -1.23529219 -0.02779435]\n",
      " [-0.0174104  -1.04761905 -1.34811502  0.00829055  1.48826136]\n",
      " [-0.0174104   0.14285714  1.21159704 -1.23529219 -0.40680828]\n",
      " [ 1.28836988  0.14285714  1.21159704 -1.23529219  1.10924743]\n",
      " [-1.32319068 -1.04761905 -1.34811502 -1.23529219 -0.40680828]\n",
      " [-0.0174104   1.33333333 -0.06825899  1.2518733   1.10924743]\n",
      " [-0.0174104  -1.04761905 -0.06825899  0.00829055 -0.40680828]\n",
      " [-0.0174104  -1.04761905 -1.34811502 -1.23529219 -1.16483614]\n",
      " [-0.0174104   0.14285714 -0.06825899  1.2518733   0.35121957]\n",
      " [ 1.28836988  0.14285714 -1.34811502  1.2518733  -1.16483614]\n",
      " [-0.0174104   1.33333333  1.21159704  1.2518733   1.10924743]\n",
      " [ 1.28836988  1.33333333 -0.06825899  0.00829055 -0.78582221]\n",
      " [-1.32319068 -1.04761905 -1.34811502  1.2518733   1.48826136]\n",
      " [-1.32319068  0.14285714  1.21159704  0.00829055 -1.54385007]\n",
      " [ 1.28836988 -1.04761905 -1.34811502  1.2518733  -0.40680828]\n",
      " [ 1.28836988  0.14285714 -1.34811502  1.2518733   1.48826136]\n",
      " [ 1.28836988 -1.04761905  1.21159704  0.00829055 -0.40680828]\n",
      " [-0.0174104   1.33333333  1.21159704  0.00829055  0.35121957]\n",
      " [-0.0174104  -1.04761905  1.21159704  0.00829055 -0.40680828]\n",
      " [-0.0174104   1.33333333 -1.34811502  1.2518733   1.10924743]\n",
      " [-0.0174104  -1.04761905  1.21159704 -1.23529219 -1.54385007]\n",
      " [ 1.28836988  0.14285714 -0.06825899  1.2518733   0.35121957]\n",
      " [-1.32319068  1.33333333 -1.34811502 -1.23529219  0.7302335 ]\n",
      " [-0.0174104   0.14285714  1.21159704 -1.23529219  1.48826136]\n",
      " [ 1.28836988  1.33333333 -0.06825899  0.00829055 -1.54385007]\n",
      " [-1.32319068  0.14285714  1.21159704  0.00829055 -1.16483614]\n",
      " [-1.32319068  0.14285714 -0.06825899  1.2518733   0.7302335 ]\n",
      " [ 1.28836988  1.33333333  1.21159704  0.00829055 -0.02779435]\n",
      " [ 1.28836988 -1.04761905  1.21159704  1.2518733  -0.78582221]\n",
      " [ 1.28836988 -1.04761905  1.21159704  1.2518733  -1.54385007]\n",
      " [ 1.28836988 -1.04761905 -0.06825899 -1.23529219 -1.54385007]\n",
      " [-0.0174104   1.33333333 -0.06825899 -1.23529219  0.7302335 ]\n",
      " [-1.32319068 -1.04761905 -0.06825899  1.2518733  -0.02779435]\n",
      " [-1.32319068 -1.04761905  1.21159704  1.2518733   0.7302335 ]\n",
      " [-0.0174104  -1.04761905  1.21159704  1.2518733  -0.02779435]\n",
      " [ 1.28836988 -1.04761905  1.21159704  0.00829055  1.10924743]\n",
      " [-1.32319068  1.33333333 -1.34811502  0.00829055 -1.16483614]\n",
      " [-1.32319068 -1.04761905 -0.06825899 -1.23529219  0.7302335 ]\n",
      " [-1.32319068 -1.04761905  1.21159704  1.2518733  -1.16483614]\n",
      " [-0.0174104   1.33333333 -0.06825899  0.00829055 -0.02779435]\n",
      " [-0.0174104  -1.04761905  1.21159704  0.00829055 -0.78582221]\n",
      " [-0.0174104  -1.04761905  1.21159704 -1.23529219  0.35121957]\n",
      " [-0.0174104   0.14285714 -0.06825899  0.00829055  0.35121957]\n",
      " [-0.0174104  -1.04761905 -1.34811502  0.00829055  1.48826136]\n",
      " [-1.32319068 -1.04761905  1.21159704  1.2518733  -1.54385007]\n",
      " [ 1.28836988  0.14285714 -1.34811502  1.2518733   0.7302335 ]\n",
      " [-1.32319068  0.14285714 -0.06825899  1.2518733   0.35121957]\n",
      " [ 1.28836988 -1.04761905 -0.06825899 -1.23529219 -1.16483614]\n",
      " [-0.0174104  -1.04761905  1.21159704 -1.23529219 -1.16483614]\n",
      " [-0.0174104  -1.04761905 -0.06825899 -1.23529219 -0.78582221]\n",
      " [ 1.28836988  0.14285714 -0.06825899 -1.23529219  0.35121957]\n",
      " [-1.32319068 -1.04761905 -0.06825899  0.00829055  1.10924743]\n",
      " [-0.0174104   1.33333333 -0.06825899  1.2518733  -1.54385007]\n",
      " [-1.32319068 -1.04761905 -1.34811502  0.00829055 -0.40680828]\n",
      " [ 1.28836988  1.33333333 -0.06825899  0.00829055  0.7302335 ]\n",
      " [ 1.28836988 -1.04761905 -0.06825899 -1.23529219  0.35121957]\n",
      " [-0.0174104   0.14285714 -0.06825899  1.2518733  -1.54385007]\n",
      " [ 1.28836988  0.14285714 -0.06825899 -1.23529219 -0.40680828]\n",
      " [-1.32319068 -1.04761905 -0.06825899  0.00829055  0.7302335 ]\n",
      " [-1.32319068  1.33333333  1.21159704 -1.23529219 -0.78582221]\n",
      " [-1.32319068 -1.04761905 -0.06825899 -1.23529219  1.10924743]\n",
      " [-1.32319068  0.14285714  1.21159704  0.00829055 -0.78582221]\n",
      " [ 1.28836988 -1.04761905 -0.06825899  0.00829055 -0.40680828]\n",
      " [-0.0174104   0.14285714 -0.06825899  1.2518733  -0.40680828]\n",
      " [-0.0174104  -1.04761905  1.21159704 -1.23529219  0.7302335 ]\n",
      " [ 1.28836988  0.14285714  1.21159704  0.00829055 -0.02779435]\n",
      " [ 1.28836988  1.33333333 -1.34811502  0.00829055  0.35121957]\n",
      " [ 1.28836988  0.14285714  1.21159704  0.00829055  0.7302335 ]\n",
      " [-0.0174104  -1.04761905  1.21159704  1.2518733   1.10924743]\n",
      " [ 1.28836988  0.14285714  1.21159704  1.2518733  -0.40680828]]\n"
     ]
    }
   ],
   "source": [
    "# llama featureNormalize con los datos cargados\n",
    "X_norm, mu, sigma = featureNormalize(X)\n",
    "\n",
    "print(X)\n",
    "print('Media calculada:', mu)\n",
    "print('Desviación estandar calculada:', sigma)\n",
    "print(X_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despues de `featureNormalize` la funcion es provada, se añade el temino de interseccion a `X_norm`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Añade el termino de interseccion a X\n",
    "# (Columna de unos para X0)\n",
    "X = np.concatenate([np.ones((m, 1)), X_norm], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          1.28836988  0.14285714 -0.06825899  0.00829055  1.48826136]\n",
      " [ 1.         -0.0174104  -1.04761905 -1.34811502  0.00829055  1.48826136]\n",
      " [ 1.         -1.32319068  1.33333333 -1.34811502  1.2518733  -1.54385007]\n",
      " [ 1.         -0.0174104  -1.04761905 -0.06825899 -1.23529219 -1.16483614]\n",
      " [ 1.         -1.32319068  1.33333333 -1.34811502  0.00829055  1.48826136]\n",
      " [ 1.          1.28836988 -1.04761905 -1.34811502  1.2518733   1.48826136]\n",
      " [ 1.          1.28836988 -1.04761905 -1.34811502 -1.23529219  0.35121957]\n",
      " [ 1.         -0.0174104   0.14285714 -0.06825899 -1.23529219  1.48826136]\n",
      " [ 1.         -0.0174104  -1.04761905 -1.34811502  0.00829055 -0.02779435]\n",
      " [ 1.          1.28836988  0.14285714 -1.34811502  0.00829055 -0.02779435]\n",
      " [ 1.         -1.32319068  0.14285714  1.21159704  0.00829055  0.35121957]\n",
      " [ 1.         -1.32319068 -1.04761905 -0.06825899 -1.23529219 -0.02779435]\n",
      " [ 1.          1.28836988  1.33333333  1.21159704  0.00829055  1.10924743]\n",
      " [ 1.         -0.0174104  -1.04761905  1.21159704  0.00829055 -1.54385007]\n",
      " [ 1.          1.28836988  1.33333333  1.21159704  0.00829055 -0.40680828]\n",
      " [ 1.         -1.32319068 -1.04761905 -1.34811502  0.00829055 -1.54385007]\n",
      " [ 1.          1.28836988 -1.04761905 -0.06825899  1.2518733   1.10924743]\n",
      " [ 1.          1.28836988  1.33333333 -1.34811502 -1.23529219 -0.40680828]\n",
      " [ 1.          1.28836988 -1.04761905 -1.34811502  0.00829055 -0.02779435]\n",
      " [ 1.          1.28836988  1.33333333  1.21159704  1.2518733   1.10924743]\n",
      " [ 1.          1.28836988  1.33333333 -0.06825899  1.2518733   0.35121957]\n",
      " [ 1.         -0.0174104   0.14285714 -0.06825899  0.00829055  0.7302335 ]\n",
      " [ 1.         -1.32319068 -1.04761905 -0.06825899  0.00829055 -0.02779435]\n",
      " [ 1.          1.28836988  1.33333333 -0.06825899 -1.23529219  0.35121957]\n",
      " [ 1.         -0.0174104   1.33333333  1.21159704  0.00829055  1.48826136]\n",
      " [ 1.         -1.32319068 -1.04761905  1.21159704 -1.23529219 -1.54385007]\n",
      " [ 1.         -0.0174104   0.14285714 -0.06825899  0.00829055 -0.40680828]\n",
      " [ 1.         -0.0174104   1.33333333 -1.34811502  1.2518733  -0.78582221]\n",
      " [ 1.         -1.32319068 -1.04761905 -1.34811502 -1.23529219 -1.54385007]\n",
      " [ 1.         -0.0174104   1.33333333  1.21159704  1.2518733  -0.78582221]\n",
      " [ 1.         -0.0174104   0.14285714 -0.06825899 -1.23529219 -0.02779435]\n",
      " [ 1.         -1.32319068  0.14285714  1.21159704 -1.23529219 -0.78582221]\n",
      " [ 1.         -0.0174104  -1.04761905 -1.34811502 -1.23529219  1.10924743]\n",
      " [ 1.         -1.32319068 -1.04761905 -0.06825899 -1.23529219  0.35121957]\n",
      " [ 1.         -0.0174104   1.33333333 -0.06825899 -1.23529219 -1.54385007]\n",
      " [ 1.          1.28836988  1.33333333  1.21159704 -1.23529219  1.48826136]\n",
      " [ 1.         -0.0174104   1.33333333 -1.34811502  1.2518733  -0.78582221]\n",
      " [ 1.         -0.0174104   0.14285714 -0.06825899  0.00829055 -0.02779435]\n",
      " [ 1.         -1.32319068  1.33333333 -0.06825899 -1.23529219  0.7302335 ]\n",
      " [ 1.         -0.0174104   1.33333333 -1.34811502  0.00829055  1.48826136]\n",
      " [ 1.          1.28836988  1.33333333 -1.34811502  1.2518733  -1.16483614]\n",
      " [ 1.         -0.0174104   0.14285714  1.21159704 -1.23529219 -1.54385007]\n",
      " [ 1.         -0.0174104  -1.04761905 -0.06825899  0.00829055  1.48826136]\n",
      " [ 1.          1.28836988  0.14285714  1.21159704 -1.23529219 -1.54385007]\n",
      " [ 1.         -0.0174104   1.33333333 -1.34811502  1.2518733  -1.54385007]\n",
      " [ 1.         -1.32319068 -1.04761905 -0.06825899  0.00829055  1.48826136]\n",
      " [ 1.          1.28836988 -1.04761905 -1.34811502 -1.23529219 -0.02779435]\n",
      " [ 1.         -1.32319068 -1.04761905 -0.06825899  0.00829055 -1.16483614]\n",
      " [ 1.         -0.0174104   0.14285714  1.21159704 -1.23529219  1.48826136]\n",
      " [ 1.         -1.32319068  1.33333333  1.21159704  1.2518733   1.48826136]\n",
      " [ 1.         -1.32319068 -1.04761905 -0.06825899 -1.23529219  1.10924743]\n",
      " [ 1.         -1.32319068 -1.04761905 -0.06825899  1.2518733  -0.78582221]\n",
      " [ 1.         -0.0174104  -1.04761905 -0.06825899  0.00829055 -0.40680828]\n",
      " [ 1.         -0.0174104   0.14285714  1.21159704  1.2518733  -0.78582221]\n",
      " [ 1.         -0.0174104   1.33333333  1.21159704 -1.23529219 -1.54385007]\n",
      " [ 1.         -1.32319068 -1.04761905  1.21159704 -1.23529219 -1.54385007]\n",
      " [ 1.         -0.0174104   1.33333333  1.21159704 -1.23529219 -0.78582221]\n",
      " [ 1.          1.28836988  1.33333333 -1.34811502 -1.23529219  0.35121957]\n",
      " [ 1.         -1.32319068  1.33333333 -0.06825899  1.2518733  -0.02779435]\n",
      " [ 1.         -0.0174104   0.14285714 -1.34811502  1.2518733  -1.54385007]\n",
      " [ 1.         -1.32319068  0.14285714 -0.06825899  1.2518733   0.35121957]\n",
      " [ 1.         -0.0174104   1.33333333 -0.06825899  1.2518733  -1.16483614]\n",
      " [ 1.         -0.0174104  -1.04761905 -1.34811502  0.00829055 -0.02779435]\n",
      " [ 1.         -0.0174104   0.14285714 -0.06825899  1.2518733   1.10924743]\n",
      " [ 1.         -1.32319068 -1.04761905 -1.34811502  0.00829055  1.10924743]\n",
      " [ 1.         -0.0174104   1.33333333 -1.34811502  1.2518733   1.48826136]\n",
      " [ 1.         -1.32319068  0.14285714  1.21159704  0.00829055  1.10924743]\n",
      " [ 1.         -0.0174104   1.33333333 -1.34811502  1.2518733  -0.02779435]\n",
      " [ 1.          1.28836988  0.14285714 -0.06825899  0.00829055  1.48826136]\n",
      " [ 1.         -1.32319068  0.14285714 -0.06825899 -1.23529219  0.35121957]\n",
      " [ 1.         -0.0174104   1.33333333 -0.06825899  0.00829055  0.7302335 ]\n",
      " [ 1.          1.28836988  1.33333333 -0.06825899  1.2518733  -0.40680828]\n",
      " [ 1.         -1.32319068  1.33333333 -0.06825899 -1.23529219  0.7302335 ]\n",
      " [ 1.         -0.0174104   0.14285714 -1.34811502  0.00829055 -0.78582221]\n",
      " [ 1.         -1.32319068 -1.04761905  1.21159704 -1.23529219  0.7302335 ]\n",
      " [ 1.          1.28836988  1.33333333  1.21159704 -1.23529219 -0.78582221]\n",
      " [ 1.         -0.0174104  -1.04761905 -1.34811502  1.2518733   1.10924743]\n",
      " [ 1.         -0.0174104  -1.04761905  1.21159704  1.2518733  -0.02779435]\n",
      " [ 1.         -0.0174104  -1.04761905 -0.06825899  1.2518733  -1.54385007]\n",
      " [ 1.         -0.0174104  -1.04761905 -1.34811502  0.00829055 -0.02779435]\n",
      " [ 1.          1.28836988  0.14285714 -1.34811502 -1.23529219 -0.02779435]\n",
      " [ 1.         -0.0174104  -1.04761905 -1.34811502  0.00829055  1.48826136]\n",
      " [ 1.         -0.0174104   0.14285714  1.21159704 -1.23529219 -0.40680828]\n",
      " [ 1.          1.28836988  0.14285714  1.21159704 -1.23529219  1.10924743]\n",
      " [ 1.         -1.32319068 -1.04761905 -1.34811502 -1.23529219 -0.40680828]\n",
      " [ 1.         -0.0174104   1.33333333 -0.06825899  1.2518733   1.10924743]\n",
      " [ 1.         -0.0174104  -1.04761905 -0.06825899  0.00829055 -0.40680828]\n",
      " [ 1.         -0.0174104  -1.04761905 -1.34811502 -1.23529219 -1.16483614]\n",
      " [ 1.         -0.0174104   0.14285714 -0.06825899  1.2518733   0.35121957]\n",
      " [ 1.          1.28836988  0.14285714 -1.34811502  1.2518733  -1.16483614]\n",
      " [ 1.         -0.0174104   1.33333333  1.21159704  1.2518733   1.10924743]\n",
      " [ 1.          1.28836988  1.33333333 -0.06825899  0.00829055 -0.78582221]\n",
      " [ 1.         -1.32319068 -1.04761905 -1.34811502  1.2518733   1.48826136]\n",
      " [ 1.         -1.32319068  0.14285714  1.21159704  0.00829055 -1.54385007]\n",
      " [ 1.          1.28836988 -1.04761905 -1.34811502  1.2518733  -0.40680828]\n",
      " [ 1.          1.28836988  0.14285714 -1.34811502  1.2518733   1.48826136]\n",
      " [ 1.          1.28836988 -1.04761905  1.21159704  0.00829055 -0.40680828]\n",
      " [ 1.         -0.0174104   1.33333333  1.21159704  0.00829055  0.35121957]\n",
      " [ 1.         -0.0174104  -1.04761905  1.21159704  0.00829055 -0.40680828]\n",
      " [ 1.         -0.0174104   1.33333333 -1.34811502  1.2518733   1.10924743]\n",
      " [ 1.         -0.0174104  -1.04761905  1.21159704 -1.23529219 -1.54385007]\n",
      " [ 1.          1.28836988  0.14285714 -0.06825899  1.2518733   0.35121957]\n",
      " [ 1.         -1.32319068  1.33333333 -1.34811502 -1.23529219  0.7302335 ]\n",
      " [ 1.         -0.0174104   0.14285714  1.21159704 -1.23529219  1.48826136]\n",
      " [ 1.          1.28836988  1.33333333 -0.06825899  0.00829055 -1.54385007]\n",
      " [ 1.         -1.32319068  0.14285714  1.21159704  0.00829055 -1.16483614]\n",
      " [ 1.         -1.32319068  0.14285714 -0.06825899  1.2518733   0.7302335 ]\n",
      " [ 1.          1.28836988  1.33333333  1.21159704  0.00829055 -0.02779435]\n",
      " [ 1.          1.28836988 -1.04761905  1.21159704  1.2518733  -0.78582221]\n",
      " [ 1.          1.28836988 -1.04761905  1.21159704  1.2518733  -1.54385007]\n",
      " [ 1.          1.28836988 -1.04761905 -0.06825899 -1.23529219 -1.54385007]\n",
      " [ 1.         -0.0174104   1.33333333 -0.06825899 -1.23529219  0.7302335 ]\n",
      " [ 1.         -1.32319068 -1.04761905 -0.06825899  1.2518733  -0.02779435]\n",
      " [ 1.         -1.32319068 -1.04761905  1.21159704  1.2518733   0.7302335 ]\n",
      " [ 1.         -0.0174104  -1.04761905  1.21159704  1.2518733  -0.02779435]\n",
      " [ 1.          1.28836988 -1.04761905  1.21159704  0.00829055  1.10924743]\n",
      " [ 1.         -1.32319068  1.33333333 -1.34811502  0.00829055 -1.16483614]\n",
      " [ 1.         -1.32319068 -1.04761905 -0.06825899 -1.23529219  0.7302335 ]\n",
      " [ 1.         -1.32319068 -1.04761905  1.21159704  1.2518733  -1.16483614]\n",
      " [ 1.         -0.0174104   1.33333333 -0.06825899  0.00829055 -0.02779435]\n",
      " [ 1.         -0.0174104  -1.04761905  1.21159704  0.00829055 -0.78582221]\n",
      " [ 1.         -0.0174104  -1.04761905  1.21159704 -1.23529219  0.35121957]\n",
      " [ 1.         -0.0174104   0.14285714 -0.06825899  0.00829055  0.35121957]\n",
      " [ 1.         -0.0174104  -1.04761905 -1.34811502  0.00829055  1.48826136]\n",
      " [ 1.         -1.32319068 -1.04761905  1.21159704  1.2518733  -1.54385007]\n",
      " [ 1.          1.28836988  0.14285714 -1.34811502  1.2518733   0.7302335 ]\n",
      " [ 1.         -1.32319068  0.14285714 -0.06825899  1.2518733   0.35121957]\n",
      " [ 1.          1.28836988 -1.04761905 -0.06825899 -1.23529219 -1.16483614]\n",
      " [ 1.         -0.0174104  -1.04761905  1.21159704 -1.23529219 -1.16483614]\n",
      " [ 1.         -0.0174104  -1.04761905 -0.06825899 -1.23529219 -0.78582221]\n",
      " [ 1.          1.28836988  0.14285714 -0.06825899 -1.23529219  0.35121957]\n",
      " [ 1.         -1.32319068 -1.04761905 -0.06825899  0.00829055  1.10924743]\n",
      " [ 1.         -0.0174104   1.33333333 -0.06825899  1.2518733  -1.54385007]\n",
      " [ 1.         -1.32319068 -1.04761905 -1.34811502  0.00829055 -0.40680828]\n",
      " [ 1.          1.28836988  1.33333333 -0.06825899  0.00829055  0.7302335 ]\n",
      " [ 1.          1.28836988 -1.04761905 -0.06825899 -1.23529219  0.35121957]\n",
      " [ 1.         -0.0174104   0.14285714 -0.06825899  1.2518733  -1.54385007]\n",
      " [ 1.          1.28836988  0.14285714 -0.06825899 -1.23529219 -0.40680828]\n",
      " [ 1.         -1.32319068 -1.04761905 -0.06825899  0.00829055  0.7302335 ]\n",
      " [ 1.         -1.32319068  1.33333333  1.21159704 -1.23529219 -0.78582221]\n",
      " [ 1.         -1.32319068 -1.04761905 -0.06825899 -1.23529219  1.10924743]\n",
      " [ 1.         -1.32319068  0.14285714  1.21159704  0.00829055 -0.78582221]\n",
      " [ 1.          1.28836988 -1.04761905 -0.06825899  0.00829055 -0.40680828]\n",
      " [ 1.         -0.0174104   0.14285714 -0.06825899  1.2518733  -0.40680828]\n",
      " [ 1.         -0.0174104  -1.04761905  1.21159704 -1.23529219  0.7302335 ]\n",
      " [ 1.          1.28836988  0.14285714  1.21159704  0.00829055 -0.02779435]\n",
      " [ 1.          1.28836988  1.33333333 -1.34811502  0.00829055  0.35121957]\n",
      " [ 1.          1.28836988  0.14285714  1.21159704  0.00829055  0.7302335 ]\n",
      " [ 1.         -0.0174104  -1.04761905  1.21159704  1.2518733   1.10924743]\n",
      " [ 1.          1.28836988  0.14285714  1.21159704  1.2518733  -0.40680828]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section5\"></a>\n",
    "### 2.2 Descenso por el gradiente\n",
    "\n",
    "En el ejemplo anterior se implemento el descenso por el gradiente para un problema de regresion univariable. La unica diferencia es que ahora existe una caracteristica adicional en la matriz $X$. La función de hipótesis y la regla de actualización del descenso del gradiente por lotes permanecen sin cambios.\n",
    "\n",
    "La implementacion de las funciones `computeCostMulti` y `gradientDescentMulti` son similares a la funcion de costo y función de descenso por el gradiente de la regresión lineal multiple es similar al de la regresion lineal multivariable. Es importante garantizar que el codigo soporte cualquier numero de caracteristicas y esten bien vectorizadas.\n",
    "\n",
    "Se puede utilizar `shape`, propiedad de los arrays `numpy`, para identificar cuantas caracteristicas estan consideradas en el dataset.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "**Nota de implementación:** En el caso de multivariables, la función de costo puede se escrita considerando la forma vectorizada de la siguiente manera:\n",
    "\n",
    "$$ J(\\theta) = \\frac{1}{2m}(X\\theta - \\vec{y})^T(X\\theta - \\vec{y}) $$\n",
    "\n",
    "donde:\n",
    "\n",
    "$$ X = \\begin{pmatrix}\n",
    "          - (x^{(1)})^T - \\\\\n",
    "          - (x^{(2)})^T - \\\\\n",
    "          \\vdots \\\\\n",
    "          - (x^{(m)})^T - \\\\ \\\\\n",
    "        \\end{pmatrix} \\qquad \\mathbf{y} = \\begin{bmatrix} y^{(1)} \\\\ y^{(2)} \\\\ \\vdots \\\\ y^{(m)} \\\\\\end{bmatrix}$$\n",
    "\n",
    "La version vectorizada es eficiente cuando se trabaja con herramientas de calculo numericos computacional como `numpy`. \n",
    "</div>\n",
    "\n",
    "<a id=\"computeCostMulti\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeCostMulti(X, y, theta):\n",
    "    # Inicializa algunos valores utiles\n",
    "    m = y.shape[0] # numero de ejemplos de entrenamiento\n",
    "    \n",
    "    J = 0\n",
    "    \n",
    "    h = np.dot(X, theta)\n",
    "    \n",
    "    J = (1/(2 * m)) * np.sum(np.square(np.dot(X, theta) - y))\n",
    "    \n",
    "    return J\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescentMulti(X, y, theta, alpha, num_iters):\n",
    "    \n",
    "    # Inicializa algunos valores \n",
    "    m = y.shape[0] # numero de ejemplos de entrenamiento\n",
    "    \n",
    "    # realiza una copia de theta, el cual será acutalizada por el descenso por el gradiente\n",
    "    theta = theta.copy()\n",
    "    \n",
    "    J_history = []\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        theta = theta - (alpha / m) * (np.dot(X, theta) - y).dot(X)\n",
    "        J_history.append(computeCostMulti(X, y, theta))\n",
    "    \n",
    "    return theta, J_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 Seleccionando coheficientes de aprendizaje\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta calculado por el descenso por el gradiente: [191.69305735  90.13669877   6.72106621  10.83312187  12.07360172\n",
      "   7.7751037 ]\n",
      "[2, 2, 20, 3, 5]\n",
      "El precio predecido para una casa de 1650 sq-ft y 3 dormitorios (usando el descenso por el gradiente): $206\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Elegir algun valor para alpha (probar varias alternativas)\n",
    "alpha = 0.01\n",
    "num_iters = 1000\n",
    "\n",
    "# inicializa theta y ejecuta el descenso por el gradiente\n",
    "theta = np.zeros(6)\n",
    "theta, J_history = gradientDescentMulti(X, y, theta, alpha, num_iters)\n",
    "\n",
    "# Grafica la convergencia del costo\n",
    "pyplot.plot(np.arange(len(J_history)), J_history, lw=6)\n",
    "pyplot.xlabel('Numero de iteraciones')\n",
    "pyplot.ylabel('Costo J')\n",
    "\n",
    "# Muestra los resultados del descenso por el gradiente\n",
    "print('theta calculado por el descenso por el gradiente: {:s}'.format(str(theta)))\n",
    "\n",
    "# Estimar el precio para una casa de 1650 sq-ft, con 3 dormitorios\n",
    "X_array = [1, 2, 2, 20, 3, 5]\n",
    "print(X_array[1:6])\n",
    "X_array[1:6] = (X_array[1:6] - mu) / sigma\n",
    "price = np.dot(X_array, theta)   # Se debe cambiar esto\n",
    "\n",
    "print('El precio predecido para una casa de 1650 sq-ft y 3 dormitorios (usando el descenso por el gradiente): ${:.0f}'.format(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_array = [1, 2, 2, 20, 3, 5]\n",
    "X_array[1:6] = (X_array[1:6] - mu) / sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.017410403735403736,\n",
       " 0.14285714285714302,\n",
       " -1.3481150152530068,\n",
       " 2.4954560395685084,\n",
       " -0.027794354832321254]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_array[1:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section7\"></a>\n",
    "### 2.3 Ecuacion de la Normal\n",
    "\n",
    "Una manera de calcular rapidamente el modelo de una regresion lineal es:\n",
    "\n",
    "$$ \\theta = \\left( X^T X\\right)^{-1} X^T\\vec{y}$$\n",
    "\n",
    "Utilizando esta formula no requiere que se escale ninguna caracteristica, y se obtendra una solucion exacta con un solo calculo: no hay “bucles de convergencia” como en el descenso por el gradiente. \n",
    "\n",
    "Primero se recargan los datos para garantizar que las variables no esten modificadas. Recordar que no es necesario escalar las caracteristicas, se debe agregar la columna de unos a la matriz $X$ para tener el termino de intersección($\\theta_0$). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos\n",
    "#data = np.loadtxt(os.path.join('Datasets', 'ex1data2.txt'), delimiter=',')\n",
    "data = np.loadtxt(os.path.join('data_cobro.txt'), delimiter=',')\n",
    "X = data[:, :5]\n",
    "y = data[:, 5]\n",
    "m = y.size\n",
    "X = np.concatenate([np.ones((m, 1)), X], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalEqn(X, y):\n",
    "  \n",
    "    theta = np.zeros(X.shape[1])\n",
    "    \n",
    "    theta = np.dot(np.dot(np.linalg.inv(np.dot(X.T,X)),X.T),y)\n",
    "    \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta calculado a partir de la ecuación de la normal: [-118.67366475  117.71548563    7.98442969    0.69363695   15.02308795\n",
      "    2.94785828]\n",
      "Esto es [-118.67366475  117.71548563    7.98442969    0.69363695   15.02308795\n",
      "    2.94785828]\n",
      "Precio MG 2D, Standar, 20s, Musica y voz en off, 5 revisiones es (usando la ecuación de la normal): $206\n"
     ]
    }
   ],
   "source": [
    "# Calcula los parametros con la ecuación de la normal\n",
    "theta = normalEqn(X, y);\n",
    "\n",
    "# Muestra los resultados optenidos a partir de la aplicación de la ecuación de la normal\n",
    "print('Theta calculado a partir de la ecuación de la normal: {:s}'.format(str(theta)));\n",
    "\n",
    "# Estimar el precio para una casa de superficie de 1650 sq-ft y tres dormitorios\n",
    "print(f'Esto es {theta}')\n",
    "X_array = [1, 2, 2, 20, 3, 5]\n",
    "price = np.dot(X_array, theta) \n",
    "\n",
    "print('Precio MG 2D, Standar, 20s, Musica y voz en off, 5 revisiones es (usando la ecuación de la normal): ${:.0f}'.format(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
